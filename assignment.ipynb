{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import wave\n",
    "import pyaudio\n",
    "import numpy as np\n",
    "import requests\n",
    "import queue\n",
    "import threading\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.cloud import speech\n",
    "from stream_wave import stream_wave\n",
    "from play_audio import play_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the GenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Speech-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "global_transcription = \"\"\n",
    "stream_active = False\n",
    "\n",
    "# Audio parameters\n",
    "STREAMING_LIMIT = 240000  # 4 minutes\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_SIZE = int(SAMPLE_RATE / 10)  # 100ms\n",
    "\n",
    "class ResumableMicrophoneStream:\n",
    "    def __init__(self, rate, chunk_size):\n",
    "        self._rate = rate\n",
    "        self.chunk_size = chunk_size\n",
    "        self._num_channels = 1\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=self._num_channels,\n",
    "            rate=self._rate,\n",
    "            input=True,\n",
    "            frames_per_buffer=self.chunk_size,\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.closed = False\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, *args, **kwargs):\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            yield chunk\n",
    "\n",
    "\n",
    "def transcribe_audio():\n",
    "    global global_transcription, stream_active\n",
    "    client = speech.SpeechClient()\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=SAMPLE_RATE,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "    streaming_config = speech.StreamingRecognitionConfig(\n",
    "        config=config, interim_results=True\n",
    "    )\n",
    "\n",
    "    with ResumableMicrophoneStream(SAMPLE_RATE, CHUNK_SIZE) as stream:\n",
    "        audio_generator = stream.generator()\n",
    "        requests = (\n",
    "            speech.StreamingRecognizeRequest(audio_content=content)\n",
    "            for content in audio_generator\n",
    "        )\n",
    "        responses = client.streaming_recognize(streaming_config, requests)\n",
    "\n",
    "        for response in responses:\n",
    "            if not response.results:\n",
    "                continue\n",
    "\n",
    "            result = response.results[0]\n",
    "            if not result.alternatives:\n",
    "                continue\n",
    "\n",
    "            transcript = result.alternatives[0].transcript.strip()\n",
    "\n",
    "            if result.is_final:\n",
    "                global_transcription += transcript + \" \"\n",
    "                if re.search(r\"\\b(exit|quit)\\b\", transcript, re.I):\n",
    "                    stream_active = False\n",
    "                    break\n",
    "\n",
    "    stream_active = False\n",
    "\n",
    "\n",
    "def start_stream():\n",
    "    global stream_active, global_transcription\n",
    "    global_transcription = \"\" \n",
    "    if not stream_active:\n",
    "        stream_active = True\n",
    "        threading.Thread(target=transcribe_audio, daemon=True).start()\n",
    "    return \"Listening... Say 'Exit' to stop.\"\n",
    "\n",
    "\n",
    "def stop_stream():\n",
    "    global stream_active\n",
    "    stream_active = False\n",
    "    return \"Transcription Stopped.\\nFinal text: \" + global_transcription\n",
    "\n",
    "\n",
    "def reset_transcription():\n",
    "    global global_transcription\n",
    "    global_transcription = \"\"\n",
    "    return \"Transcription reset.\"\n",
    "\n",
    "\n",
    "def view_transcription():\n",
    "    return global_transcription\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authorization\n",
    "### Note: You can give the author of this repository your email for accessing the app such that your token.json could be created. Currently only author email works in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os.path\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from google.generativeai.types import FunctionDeclaration, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCOPES = [\"https://www.googleapis.com/auth/calendar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = None\n",
    "if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\n",
    "            \"credentials.json\", SCOPES\n",
    "        )\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open(\"token.json\", \"w\") as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "service = build(\"calendar\", \"v3\", credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events():\n",
    "  now = datetime.datetime.now(tz=datetime.timezone.utc).isoformat()\n",
    "  print(\"Getting the upcoming events\")\n",
    "  events_result = (\n",
    "        service.events()\n",
    "        .list(\n",
    "            calendarId=\"primary\",\n",
    "            timeMin=now,\n",
    "            maxResults=5,\n",
    "            singleEvents=True,\n",
    "            orderBy=\"startTime\",\n",
    "            ).execute()\n",
    "      )\n",
    "  events = events_result.get(\"items\", [])\n",
    "\n",
    "  if not events:\n",
    "    print(\"No upcoming events found.\")\n",
    "    return []\n",
    "\n",
    "\n",
    "  for event in events:\n",
    "    start = event[\"start\"].get(\"dateTime\", event[\"start\"].get(\"date\"))\n",
    "    print(f\"Event: {event['summary']} at {start}\")\n",
    "    return start, event['summary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_events_declarations = {\n",
    "        \"name\": \"get_upcoming_event\",\n",
    "        \"description\": \"Get the next upcoming event from Google Calendar\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upcoming_event():\n",
    "    start, events = get_events()\n",
    "    if events:\n",
    "        event = events\n",
    "        return {\n",
    "            \"summary\": event,\n",
    "            \"start\": start\n",
    "        }\n",
    "    else:\n",
    "        return {\"message\": \"No upcoming events found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_events(summary, description, start_datetime, end_datetime):\n",
    "    event = {\n",
    "        'summary': summary,\n",
    "        'location': 'At the Office',\n",
    "        'description': description,\n",
    "        'start': {\n",
    "            'dateTime': start_datetime,\n",
    "            'timeZone': 'Asia/Kolkata',\n",
    "        },\n",
    "        'end': {\n",
    "            'dateTime': end_datetime,\n",
    "            'timeZone': 'Asia/Kolkata',\n",
    "        },\n",
    "        'reminders': {\n",
    "            'useDefault': False,\n",
    "            'overrides': [\n",
    "                {'method': 'email', 'minutes': 24 * 60},\n",
    "                {'method': 'popup', 'minutes': 10},\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    event = service.events().insert(calendarId='primary', body=event).execute()\n",
    "    print('Event created: %s' % (event.get('htmlLink')))\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_events_declarations =  {\n",
    "        \"name\": \"add_calendar_event\",\n",
    "        \"description\": \"Add a new event to Google Calendar with title, description, start_datetime, end_datetime. By default take time zone as 'Asia/Kolkata' \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"summary\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Title of the event\"\n",
    "                },\n",
    "                \"description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Description of the event\"\n",
    "                },\n",
    "                \"start_datetime\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Start time in ISO 8601 format (e.g. '2025-06-28T09:00:00-07:00')\"\n",
    "                },\n",
    "                \"end_datetime\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"End time in ISO 8601 format\"\n",
    "                },\n",
    "                \n",
    "            },\n",
    "            \"required\": [\"summary\", \"description\", \"start_datetime\", \"end_datetime\"]\n",
    "        }\n",
    "    } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_calendar_event(summary, description, start_datetime, end_datetime):\n",
    "    event = add_events(\n",
    "        summary=summary,\n",
    "        description=description,\n",
    "        start_datetime=start_datetime,\n",
    "        end_datetime=end_datetime,\n",
    "    )\n",
    "    return {\"status\": \"success\", \"event_link\": event.get(\"htmlLink\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = types.Tool(function_declarations=[get_events_declarations, add_events_declarations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\245970\\.conda\\envs\\llmenv\\lib\\site-packages\\gradio\\components\\chatbot.py:237: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://814dc3df6efd5dc0a2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://814dc3df6efd5dc0a2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks(title=\"Speech Chatbot\") as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Voice Assistant\")\n",
    "    audio_waveform = gr.Audio(label=\"Assistant Waveform\", interactive=False, type='numpy')\n",
    "    \n",
    "    with gr.Row():\n",
    "        start_btn = gr.Button(\"🎤 Start Listening\")\n",
    "        stop_btn = gr.Button(\"🛑 Stop Listening\")\n",
    "        send_btn = gr.Button(\"📨 Send to Gemini\")\n",
    "        view_btn = gr.Button(\"👁️ View Transcription\")\n",
    "        reset_btn = gr.Button(\"🔄 Reset\")\n",
    "\n",
    "    chat_state = gr.State([])\n",
    "    transcription_state = gr.State(\"\")\n",
    "\n",
    "    # Button callbacks\n",
    "    def on_start(chat_history, transcription):\n",
    "        start_stream()\n",
    "        chat_history.append((\"system\", \"🎙️ Listening started... Say 'Exit' to stop.\"))\n",
    "        return chat_history, transcription\n",
    "\n",
    "    def on_stop(chat_history, transcription):\n",
    "        stop_stream()\n",
    "        chat_history.append((\"system\", \"🛑 Transcription stopped.\"))\n",
    "        return chat_history, transcription\n",
    "\n",
    "    def on_view(chat_history, transcription):\n",
    "        view = view_transcription()\n",
    "        chat_history.append((\"user\", \"View Transcription\"))\n",
    "        chat_history.append((\"assistant\", view))\n",
    "        return chat_history, view\n",
    "\n",
    "    def on_reset(chat_history, transcription):\n",
    "        reset_transcription()\n",
    "        chat_history.clear()\n",
    "        return [], \"\"\n",
    "\n",
    "    def on_send(chat_history, transcription):\n",
    "\n",
    "        user_input = view_transcription()\n",
    "        chat_history.append((\"user\", user_input))\n",
    "        \n",
    "        history = []\n",
    "        for role, msg in chat_history:\n",
    "            if role == \"system\":\n",
    "                continue\n",
    "            role = \"user\" if role == \"user\" else \"model\"\n",
    "            history.append(\n",
    "                types.Content(role=role, parts=[types.Part(text=msg)])\n",
    "            )\n",
    "\n",
    "        # Gemini response (Text)\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=history,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0.1,\n",
    "                tools=[tools]\n",
    "            )\n",
    "        )\n",
    "        reset_transcription()\n",
    "        \n",
    "        if response.candidates[0].content.parts[0].function_call:\n",
    "            function_call = response.candidates[0].content.parts[0].function_call\n",
    "            if function_call.name == 'add_calendar_event':\n",
    "                summary = function_call.args['summary']\n",
    "                description = function_call.args['description']\n",
    "                start_datetime = function_call.args['start_datetime']\n",
    "                end_datetime = function_call.args['end_datetime']\n",
    "                link = add_calendar_event(summary, description, start_datetime, end_datetime)\n",
    "                bot_response = f\"Event added to your Calender successfully {link.get('event_link')}\"\n",
    "            elif function_call.name == 'get_upcoming_event':\n",
    "                bot_response = f\"Here are your events {get_upcoming_event()}\"\n",
    "    \n",
    "        else:\n",
    "            bot_response = response.text\n",
    "        \n",
    "        chat_history.append((\"assistant\", bot_response))\n",
    "\n",
    "        # Gemini response (TTS Audio)\n",
    "        response_audio = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-preview-tts\",\n",
    "            contents=bot_response,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_modalities=[\"AUDIO\"],\n",
    "                speech_config=types.SpeechConfig(\n",
    "                    voice_config=types.VoiceConfig(\n",
    "                        prebuilt_voice_config=types.PrebuiltVoiceConfig(\n",
    "                            voice_name='Kore',\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Get inline audio as BytesIO stream\n",
    "        data = response_audio.candidates[0].content.parts[0].inline_data.data\n",
    "        audio_stream = io.BytesIO(data)\n",
    "\n",
    "        wav_stream = stream_wave(data, channels=1, rate=24000, sample_width=2)\n",
    "\n",
    "        # Play audio synchronously\n",
    "        play_audio(wav_stream)\n",
    "\n",
    "        # Reset pointer so Gradio can read it too\n",
    "        wav_stream.seek(0)\n",
    "        with wave.open(wav_stream, 'rb') as wf:\n",
    "            waveform = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)\n",
    "            sample_rate = wf.getframerate()\n",
    "        \n",
    "        \n",
    "        return chat_history, \"\", (sample_rate, waveform)\n",
    "\n",
    "    # Bind events\n",
    "    start_btn.click(on_start, [chat_state, transcription_state], [chatbot, transcription_state])\n",
    "    stop_btn.click(on_stop, [chat_state, transcription_state], [chatbot, transcription_state])\n",
    "    view_btn.click(on_view, [chat_state, transcription_state], [chatbot, transcription_state])\n",
    "    reset_btn.click(on_reset, [chat_state, transcription_state], [chatbot, transcription_state])\n",
    "    send_btn.click(\n",
    "        on_send,\n",
    "        [chat_state, transcription_state],\n",
    "        [chatbot, transcription_state, audio_waveform]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llmenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96893c8607dc97b003d35d006dea5dda501bef0f0b6219a24909f378e5a45af9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
